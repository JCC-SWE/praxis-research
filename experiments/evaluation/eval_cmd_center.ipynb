{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca32f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "#2023 questions\n",
    "#2025 questions\n",
    "#upload to blob\n",
    "#download from blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8977a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe7644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from get_qa_texts import pull_qa_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58113238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded qa-2023.txt (86034 characters)\n"
     ]
    }
   ],
   "source": [
    "data = \"qa-2023.txt\"\n",
    "qa_texts = pull_qa_texts(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "292ed90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Q: In the paper Embedding-Based Deep Neural Network and Convolutional Neural Network Graph Classifiers, what inspired the authors to use the Doc2Vec model in Natural Language Processing (NLP) for investigating different ways of graph embedding?\n",
      "    A: The authors were inspired by the Doc2Vec model in Natural Language Processing (NLP) for investigating different ways of (sub)graph embedding to represent each graph or subgraph as a fixed-length feature vector.\n",
      "\n",
      "[2] Q: In the paper Analyzing Hong Kong's Legal Judgments from a Computational Linguistics point-of-view, what methods were proposed to analyze legal judgments from Hong Kong's Court System?\n",
      "    A: The methods proposed in the paper include Citation Network Graph Generation, PageRank Algorithm, Keyword Analysis and Summarization, Sentiment Polarity, and Paragraph Classification.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# If blob returned bytes → decode; if string → parse\n",
    "if isinstance(qa_texts, (bytes, bytearray)):\n",
    "    qa_texts = qa_texts.decode(\"utf-8\")\n",
    "if isinstance(qa_texts, str):\n",
    "    qa_texts = json.loads(qa_texts)\n",
    "\n",
    "# Now qa_texts should be a list[dict]\n",
    "for i, qa in enumerate(qa_texts[:2], 1):\n",
    "    print(f\"[{i}] Q: {qa.get('question')}\\n    A: {qa.get('answer')}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fec501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C:\\Users\\joshuacubero\\Documents\\praxis-research\\phase1_model_instantiation\\func_test.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
