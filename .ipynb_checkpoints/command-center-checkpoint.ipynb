{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4c11cd-f98c-4f99-8b52-9acebb66289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phase1_model_instantiation import model_setup, func_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c4efbc-34aa-489a-bb10-1723286d7782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Qwen models:\n",
      "  qwen-2.5-3b: modified 2025-09-04 22:55:50+00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Available Qwen models:\")\n",
    "models = model_setup.list_qwen_models()\n",
    "for name, info in models.items():\n",
    "    print(f\"  {name}: modified {info['last_modified']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a201822a-29ee-4c8d-b967-641bb336d689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509ec020-d5d1-429f-96ed-5dd7085f4556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in model directory:\n",
      "  cache\n",
      "\n",
      "‚ùå config.json is missing!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_path = \"/workspace/praxis-research/base-model/qwen-2.5-3b\"\n",
    "print(\"Files in model directory:\")\n",
    "for file in os.listdir(model_path):\n",
    "    print(f\"  {file}\")\n",
    "\n",
    "# Check if config.json exists and what's in it\n",
    "config_path = os.path.join(model_path, \"config.json\")\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        import json\n",
    "        config = json.load(f)\n",
    "        print(f\"\\nConfig model_type: {config.get('model_type', 'MISSING')}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå config.json is missing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c6f9db-e4ee-413f-96f7-c600053f4bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All blobs in qwen_models/:\n",
      "  qwen_models/qwen-2.5-3b/cache/.locks/models--Qwen--Qwen2.5-3B-Instruct/07bfe0640cb5a0037f9322287fbfc682806cf672.lock (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/.locks/models--Qwen--Qwen2.5-3B-Instruct/20024bfe7c83998e9aeaf98a0cd6a2ce6306c2f0.lock (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/.locks/models--Qwen--Qwen2.5-3B-Instruct/38047c6284a25427043f0ab040f623a2a20dd093.lock (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/.locks/models--Qwen--Qwen2.5-3B-Instruct/443909a61d429dff23010e5bddd28ff530edda00.lock (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/.locks/models--Qwen--Qwen2.5-3B-Instruct/4783fe10ac3adce15ac8f358ef5462739852c569.lock (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/.locks/models--Qwen--Qwen2.5-3B-Instruct/51b83fbd4e2d363b60235b9c8d494046a83c1cbf.lock (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/.locks/models--Qwen--Qwen2.5-3B-Instruct/67347b23fb4165b652eb6611f5e1f2a06dfcddba8e909df1b2b0b1857bee06c2.lock (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/.locks/models--Qwen--Qwen2.5-3B-Instruct/a40d941d0e7e0b966ad8b62bb6d6b7c88cce1299197b599d9d0a4ce59aabfc1d.lock (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/.locks/models--Qwen--Qwen2.5-3B-Instruct/bf077f03dc569cfb8a90b3ec1ad20365a620bad6.lock (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/.no_exist/aa8e72537993ba99e69dfaafa59ed015b17504d1/added_tokens.json (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/.no_exist/aa8e72537993ba99e69dfaafa59ed015b17504d1/chat_template.jinja (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/.no_exist/aa8e72537993ba99e69dfaafa59ed015b17504d1/model.safetensors (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/.no_exist/aa8e72537993ba99e69dfaafa59ed015b17504d1/special_tokens_map.json (0 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/blobs/07bfe0640cb5a0037f9322287fbfc682806cf672 (7305 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/blobs/20024bfe7c83998e9aeaf98a0cd6a2ce6306c2f0 (1671839 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/blobs/38047c6284a25427043f0ab040f623a2a20dd093 (35581 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/blobs/443909a61d429dff23010e5bddd28ff530edda00 (7031645 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/blobs/4783fe10ac3adce15ac8f358ef5462739852c569 (2776833 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/blobs/51b83fbd4e2d363b60235b9c8d494046a83c1cbf (661 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/blobs/67347b23fb4165b652eb6611f5e1f2a06dfcddba8e909df1b2b0b1857bee06c2 (3968658944 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/blobs/a40d941d0e7e0b966ad8b62bb6d6b7c88cce1299197b599d9d0a4ce59aabfc1d (2203268048 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/blobs/bf077f03dc569cfb8a90b3ec1ad20365a620bad6 (242 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/refs/main (40 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/config.json (661 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/generation_config.json (242 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/merges.txt (1671839 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/model-00001-of-00002.safetensors (3968658944 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/model-00002-of-00002.safetensors (2203268048 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/model.safetensors.index.json (35581 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/tokenizer.json (7031645 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/tokenizer_config.json (7305 bytes)\n",
      "  qwen_models/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/vocab.json (2776833 bytes)\n",
      "  qwen_models/qwen-2.5-3b/manifest.json (4354 bytes)\n"
     ]
    }
   ],
   "source": [
    "# List all blobs in the qwen_models directory\n",
    "\n",
    "secrets = model_setup.get_secrets()\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "connection_string = f\"DefaultEndpointsProtocol=https;AccountName={secrets['storage_account_name']};AccountKey={secrets['storage_account_key']};EndpointSuffix=core.windows.net\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(secrets['container'])\n",
    "\n",
    "print(\"All blobs in qwen_models/:\")\n",
    "blobs = list(container_client.list_blobs(name_starts_with=\"qwen_models/\"))\n",
    "for blob in blobs:\n",
    "    print(f\"  {blob.name} ({blob.size} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "215df5e0-3026-4241-8843-fac1aebeebaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using cached Qwen model at /workspace/praxis-research/base-model/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1\n",
      "üîÑ Loading model and tokenizer from /workspace/praxis-research/base-model/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90b36e9af0e4e748a11c8caf9c78315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded Qwen model /workspace/praxis-research/base-model/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1\n"
     ]
    }
   ],
   "source": [
    "# Load model/tokenizer from the correct cache path\n",
    "model_path = \"/workspace/praxis-research/base-model/qwen-2.5-3b/cache/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1\"\n",
    "\n",
    "model, tokenizer = model_setup.get_qwen_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce1565e3-80ae-4b2e-95f0-229683675b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interactive QA/chat with Qwen. Type 'exit' or 'quit' to stop.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  what is a transformer in machine learning?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen: A transformer is a type of deep learning model that has become very popular for natural language processing (NLP) tasks, though it can be applied to other domains as well. The transformer architecture was introduced by Vaswani et al. in their 2017 paper \"Attention Is All You Need.\"\n",
      "\n",
      "Key features and components of the transformer include:\n",
      "\n",
      "1. **Self-Attention Mechanism**: Unlike traditional recurrent neural networks (RNNs) or convolutional neural networks (CNNs), transformers use self-attention mechanisms to weigh the importance of different input elements. This allows the model to focus on relevant parts of the input sequence without relying on sequential processing.\n",
      "\n",
      "2. **Encoder-Decoder Architecture**: Transformers typically consist of an encoder and a decoder. The encoder processes the input sequence, while the decoder generates the output sequence. This makes them suitable for tasks like machine translation where both inputs and outputs are sequences.\n",
      "\n",
      "3. **Positional Encoding**: Since the order of tokens in a sequence is crucial for many NLP tasks, transformers add positional encodings to the input embeddings to capture this information. This helps the model understand the position of each token in the sequence.\n",
      "\n",
      "4. **Feed-Forward Networks**: Transformers use feed-forward neural networks (FFNs) as part of their\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Start interactive chat\n",
    "func_test.chat_loop(model, tokenizer, system_text=\"You are a helpful AI assistant.\", max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f01740-1e11-4590-a64d-00ebd9e8315e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
